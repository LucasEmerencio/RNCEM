{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvblnWmQ-VYu"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "#coding=utf-8\n",
        "\n",
        "#  ______               _         _____      _ _ _                  _                 _         _    _  _____ _____\n",
        "# |  ____|             | |       |  __ \\    | (_| |                (_)               | |       | |  | |/ ____|  __ \\\n",
        "# | |__   ___  ___ ___ | | __ _  | |__) ___ | |_| |_ ___  ___ _ __  _  ___ __ _    __| | __ _  | |  | | (___ | |__) |\n",
        "# |  __| / __|/ __/ _ \\| |/ _` | |  ___/ _ \\| | | __/ _ \\/ __| '_ \\| |/ __/ _` |  / _` |/ _` | | |  | |\\___ \\|  ___/\n",
        "# | |____\\__ | (_| (_) | | (_| | | |  | (_) | | | ||  __| (__| | | | | (_| (_| | | (_| | (_| | | |__| |____) | |\n",
        "# |______|___/\\___\\___/|_|\\__,_| |_|   \\___/|_|_|\\__\\___|\\___|_| |_|_|\\___\\__,_|  \\__,_|\\__,_|  \\____/|_____/|_|\n",
        "# ___________________________________________________________________________________________________________________\n",
        "#                                           Testes com Outputs de fora da rede\n",
        "# ___________________________________________________________________________________________________________________\n",
        "#\n",
        "#  9848836 - Bruna Okura\n",
        "#  11913194 - Lucas Lima Emerêncio\n",
        "#  11805742 - Yann Gazzolla dos Santos\n",
        "# ___________________________________________________________________________________________________________________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cYPmIxOI3wm",
        "outputId": "fd659280-0e14-48cb-c5e4-6b7d598c4901"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# this creates a symbolic link so that now the path /content/gdrive/My\\ Drive/ is equal to /mydrive\n",
        "!ln -s /content/gdrive/My\\ Drive/ /mydrive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torch import nn\n",
        "from torchvision import models, transforms\n",
        "import subprocess\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "import json"
      ],
      "metadata": {
        "id": "mcvQgBGbCoWa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# INICIALIZANDO REDE CLASSIFICADORA"
      ],
      "metadata": {
        "id": "TP2PbQU9G8Vf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurações iniciais\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Parâmetros de entrada\n",
        "model_name = \"vgg16\"\n",
        "weights_path = \"/content/gdrive/MyDrive/TCC/Rede_Definitiva/New_detection/Weights6/vgg16_aug_pt.pth\"\n",
        "test_dir = \"/content/gdrive/MyDrive/TCC/Rede_Definitiva/New_detection/Test\"\n",
        "quiet_mode = True\n",
        "\n",
        "# Carregar o modelo\n",
        "if model_name == \"vgg16\":\n",
        "    model = models.vgg16(weights=None)\n",
        "    model.classifier[6] = nn.Linear(model.classifier[6].in_features, 6)\n",
        "else:\n",
        "    raise ValueError(f\"Modelo '{model_name}' não suportado.\")\n",
        "\n",
        "model = torch.nn.DataParallel(model)\n",
        "model.to(device)\n",
        "\n",
        "# Carregar pesos com `weights_only=True` para evitar avisos de segurança\n",
        "model.load_state_dict(torch.load(weights_path, map_location=device, weights_only=True))\n",
        "model.eval()\n",
        "\n",
        "# Transformações de pré-processamento\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Identificar classes a partir dos nomes das pastas no diretório de teste\n",
        "class_names = [\"Aedes_albopictus\", \"Aedes_fulvus\", \"Aedes_scapularis\", \"Aedes_serratus\", \"Anopheles_bellator\", \"Mansonia_humeralis\"]\n",
        "classes = {indice : name  for indice, name in enumerate(class_names)}\n"
      ],
      "metadata": {
        "id": "qiJ_aJG7xWf0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# INICIALIZANDO REDE DETECTORA"
      ],
      "metadata": {
        "id": "cS_1QSEHHAzP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# clone darknet repo\n",
        "!git clone https://github.com/LucasEmerencio/darknet_mosquito\n",
        "\n",
        "%cd darknet_mosquito\n",
        "\n",
        "!make"
      ],
      "metadata": {
        "id": "-vvWpWZDHEJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HELPER FUNCTIONS"
      ],
      "metadata": {
        "id": "dSl5puIEHRgk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_coordinates_json(result_file):\n",
        "    coordinates = []\n",
        "\n",
        "    with open(result_file, 'r') as file:\n",
        "        data = json.load(file)  # Load the JSON data\n",
        "\n",
        "        for frame in data:\n",
        "            frame_id = frame[\"frame_id\"]\n",
        "            for obj in frame[\"objects\"]:\n",
        "                relative_coords = obj[\"relative_coordinates\"]\n",
        "\n",
        "                # Extract the relative coordinates\n",
        "                center_x = relative_coords[\"center_x\"]\n",
        "                center_y = relative_coords[\"center_y\"]\n",
        "                width = relative_coords[\"width\"]\n",
        "                height = relative_coords[\"height\"]\n",
        "\n",
        "                # Add the coordinates and frame ID to the list\n",
        "                coordinates.append({\n",
        "                    \"frame_id\": frame_id,\n",
        "                    \"center_x\": center_x,\n",
        "                    \"center_y\": center_y,\n",
        "                    \"width\": width,\n",
        "                    \"height\": height\n",
        "                })\n",
        "\n",
        "    return coordinates"
      ],
      "metadata": {
        "id": "RSR7C2k_HUSA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crop_and_resize_image(path, cx, cy, range_x, range_y, crop_path = None):\n",
        "    # Load image\n",
        "    image = cv2.imread(path)\n",
        "    if image is None:\n",
        "        print(\"Error: Image not found at the specified path.\")\n",
        "        return\n",
        "\n",
        "    img_height, img_width = image.shape[:2]\n",
        "\n",
        "    #Coordenadas Absolutas\n",
        "    cx = int(cx * img_width)\n",
        "    cy = int(cy * img_height)\n",
        "\n",
        "    range_x = int(range_x * img_width)\n",
        "    range_y = int(range_y * img_height)\n",
        "\n",
        "    # Calculo do vértice superior esquerdo da caixa de crop\n",
        "    x_start = int(cx - range_x / 2)\n",
        "    y_start = int(cy - range_y / 2)\n",
        "\n",
        "    # Assegurando que as dimensões de crop respeitam os limites da imagem\n",
        "    x_start = max(0, x_start)\n",
        "    y_start = max(0, y_start)\n",
        "    x_end = min(img_width, x_start + range_x)\n",
        "    y_end = min(img_height, y_start + range_y)\n",
        "\n",
        "    # Crop the image\n",
        "    cropped_image = image[y_start:y_end, x_start:x_end]\n",
        "\n",
        "    # Resize cropped image to 512x512\n",
        "    resized_image = cv2.resize(cropped_image, (224, 224), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    #Salvamos a imagem com crop no diretório especificado se o caminho for passado para função\n",
        "    if crop_path is not None:\n",
        "      jpeg_filename = os.path.join(crop_path, f\"{os.path.splitext(os.path.basename(path))[0]}.jpg\")\n",
        "      cv2.imwrite(jpeg_filename, resized_image)\n",
        "\n",
        "    return resized_image"
      ],
      "metadata": {
        "id": "10vV5X2uHVNQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_and_crop(path):\n",
        "\n",
        "  try:\n",
        "    result = subprocess.run([\"./darknet\", \"detector\", \"test\", \"data/obj.data\", \"cfg/yolov3_custom2.cfg\", \"/content/gdrive/MyDrive/TCC/REPRODUÇÃO_DE_RESULTADOS/backup/yolov3_custom2_last.weights\", path, \"-thresh\", \"0.2\", \"-ext_output\", \"-out\", \"result.txt\"], shell = False, check = True)\n",
        "  except subprocess.CalledProcessError as e:\n",
        "    print(f\"Error during batch processing: {e}\")\n",
        "\n",
        "  coordinates = get_coordinates_json(\"result.txt\")\n",
        "  coordinates = coordinates[0]\n",
        "\n",
        "  if coordinates[\"frame_id\"] is None:\n",
        "    return None\n",
        "  else:\n",
        "    cx, cy, width, height = (\n",
        "      coordinates[\"center_x\"],\n",
        "      coordinates[\"center_y\"],\n",
        "      coordinates[\"width\"],\n",
        "      coordinates[\"height\"]\n",
        "    )\n",
        "    #crop_path é facultativo, se for omitido as images não serão salvas em outro diretório\n",
        "    imagem = crop_and_resize_image(path, cx, cy, width, height)\n",
        "\n",
        "    return imagem"
      ],
      "metadata": {
        "id": "7qJu2NieJ5j6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define helper functions\n",
        "def imShow(path):\n",
        "  %matplotlib inline\n",
        "\n",
        "  image = cv2.imread(path)\n",
        "  height, width = image.shape[:2]\n",
        "  resized_image = cv2.resize(image,(3*width, 3*height), interpolation = cv2.INTER_CUBIC)\n",
        "\n",
        "  fig = plt.gcf()\n",
        "  fig.set_size_inches(5, 5)\n",
        "  plt.axis(\"off\")\n",
        "  plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "truxy2U9OZb4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# REDE CONCATENADA"
      ],
      "metadata": {
        "id": "XceP4oenOkag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while (True):\n",
        "  try:\n",
        "    teste = input(\"Digite um caminho para uma imagem válida: \")\n",
        "    if os.path.exists(teste):\n",
        "      print(f\"Caminho do arquivo encontrado\")\n",
        "\n",
        "      valid_extensions = ['.jpg', '.jpeg']\n",
        "      if (any(teste.lower().endswith(ext) for ext in valid_extensions)):\n",
        "        print(f\"Arquivo é uma imagem\")\n",
        "        imagem = detect_and_crop(teste)\n",
        "\n",
        "        if imagem is None:\n",
        "          print(f\"Algum erro no processo, confira a imagem antes de colocar o caminho\")\n",
        "        else:\n",
        "          cv2.imwrite(\"resultado.jpg\", imagem)\n",
        "          imagem = Image.open(\"resultado.jpg\")\n",
        "          input_tensor = data_transforms(imagem).unsqueeze(0).to(device)\n",
        "\n",
        "          confidence = 6.0\n",
        "          with torch.no_grad():\n",
        "              output = model(input_tensor)\n",
        "              print(f\"logits antes do threshold = {output}\")\n",
        "              output = torch.where(output > confidence, output, torch.tensor(0.0))\n",
        "\n",
        "              if (torch.count_nonzero(output).item() != 0):\n",
        "                predicted_label = torch.argmax(output).item()\n",
        "                #print(f\"logits após threshold = {output}\")\n",
        "                print(f\"Resultado da Classificação : {classes[predicted_label]} \\n\")\n",
        "              else:\n",
        "                print(f\"Baixa confiança na predição, tente utilizar outra foto. Na eventualidade de uma segunda negativa, considerar que a espécie não está no banco de treinamento: \\n DESCONHECIDA \\n\")\n",
        "                    #imShow(\"resultado.jpg\")\n",
        "\n",
        "      else:\n",
        "        raise ValueError(\"Caminho não é de uma imagem \\n\")\n",
        "\n",
        "    else:\n",
        "      raise OSError(\"Caminho inválido \\n\")\n",
        "  except OSError as erro:\n",
        "    print(erro)\n",
        "  except ValueError as erro:\n",
        "    print(erro)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "uhukNtef_tf0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}